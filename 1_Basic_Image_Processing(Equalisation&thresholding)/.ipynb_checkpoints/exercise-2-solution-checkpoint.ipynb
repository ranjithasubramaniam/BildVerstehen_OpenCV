{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision \n",
    "\n",
    "# Exercise 2: Basic Image Processing With OpenCV\n",
    "\n",
    "- TU Chemnitz\n",
    "    - Fak. für Informatik\n",
    "        - Professur Künstliche Intelligenz\n",
    "            - Lehre\n",
    "                - Bildverstehen\n",
    "     \n",
    "Contact:\n",
    "* julien dot vitay at informatik dot tu-chemnitz dot de\n",
    "* abbas dot al-ali at informatik dot tu-chemnitz dot de\n",
    "\n",
    "Course web page:\n",
    "[https://www.tu-chemnitz.de/informatik/KI/edu/biver/](https://www.tu-chemnitz.de/informatik/KI/edu/biver/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Basic Image Processing With OpenCV\n",
    "\n",
    "## 1. OpenCV Computer Vision Library\n",
    "\n",
    "<img src=\"img/opencv.jpg\" alt=\"img/opencv.jpg\" width=\"600\"/>\n",
    "\n",
    "- Originally developed by Intel, now maintained by a fundation (BSD license)\n",
    "\n",
    "- The library is written in C++ but you can access it from Python:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "```\n",
    "\n",
    "- The official website of OpenCV is at [http://opencv.org](http://opencv.org)\n",
    "\n",
    "- The official documentation of OpenCV( C++ and Python) is at <http://docs.opencv.org/3.1.0/>\n",
    "\n",
    "- Python tutorials are at <https://docs.opencv.org/3.1.0/d6/d00/tutorial_py_root.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic IO\n",
    "\n",
    "### 2.A. Loading An Image\n",
    "\n",
    "The function `imread()` can be used to load an image from a file:\n",
    "\n",
    "```python\n",
    "img = cv2.imread('path/to/img.ext', FLAG)\n",
    "```\n",
    "- First argument is the path to the file\n",
    "- Second argument( optional) could be:\n",
    "\n",
    "    - `cv2.IMREAD_COLOR` (or 1): Loads a color image. Any transparency of image will be neglected. It is the default flag.\n",
    "    - `cv2.IMREAD_GRAYSCALE` (or 0): Loads image in grayscale mode\n",
    "    - `cv2.IMREAD_UNCHANGED` (or -1): Loads image as such including alpha channel\n",
    "    - ...\n",
    "\n",
    "- Images loaded by OpenCV are Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B Saving An Image\n",
    "\n",
    "Saving a numpy array (2D or 3D) as an image to the disk can be done using `imwrite`:\n",
    "\n",
    "```python\n",
    "cv2.imwrite('path/to/img.ext', img)\n",
    "```\n",
    "\n",
    "Most image extensions can be used: jpg, png, bmp..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.C. Displaying An Image\n",
    "\n",
    "- The simplest is to use matplotlib:\n",
    "\n",
    "```python\n",
    "plt.imshow(img [, options] )\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- OpenCV has an `imshow` function, but it is not practical.\n",
    "\n",
    "- If you want to display a color image, you have to convert it to RGB (more on that later):\n",
    "\n",
    "```python\n",
    "img_RGB = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_RGB)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now:**\n",
    "\n",
    "- Read the image file `lena.jpg` from the disk to the two variables\n",
    "    + `img_color` as a colored and\n",
    "    + `img_gray` as a gray-scaled image\n",
    "    \n",
    "- Of the two variables tell:\n",
    "    + the type of the variable\n",
    "    + the shape of the NumPy array\n",
    "    + the data type of the elemets in the array\n",
    "    + the minimum and maximum value\n",
    "\n",
    "- Save the colored image to the disk in `lena-colored.jpg`\n",
    "- Save the grayscale image to the disk in `lena-gray.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f2dcd1801657>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#import matplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#matplotlib.use('TKAgg')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline \n",
    "from __future__ import print_function\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# In color\n",
    "img_color = cv2.imread('lena.jpg')\n",
    "\n",
    "# In grayscale\n",
    "img_gray = cv2.imread('lena.jpg', 0)\n",
    "\n",
    "print(type(img_color))\n",
    "print(img_color.shape)\n",
    "print(img_color.dtype)\n",
    "print(img_color.min())\n",
    "print(img_color.max())\n",
    "\n",
    "print(type(img_gray))\n",
    "print(img_gray.shape)\n",
    "print(img_gray.dtype)\n",
    "print(img_gray.min())\n",
    "print(img_gray.max())\n",
    "\n",
    "cv2.imwrite('lena-colored.jpg', img_color)\n",
    "cv2.imwrite('lena-gray.jpg'   , img_gray )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Images From Numpy Arrays\n",
    "\n",
    "- Numpy arrays of shape (height, width) or (height, width, 3) and dtype `np.uint8` can be saved as images\n",
    "\n",
    "- If the array has another dtype, the values will be casted to `np.uint8`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.A. Creating A Grayscale Image\n",
    "\n",
    "Create a grayscale image of size 640x480, with a black background and a white 100x100 square in the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_black = np.zeros((480,640), dtype=np.uint8)\n",
    "img_white_square = img_black.copy()\n",
    "\n",
    "img_white_square[480/2-50:480/2+50,640/2-50:640/2+50] = 255\n",
    "\n",
    "cv2.imwrite('black.jpg',img_black)\n",
    "cv2.imwrite('white-square.jpg',img_white_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.B. Creating A Color Image\n",
    "\n",
    "- Create a color image of size 640x480, with a white background and a red 100x100 square in the center\n",
    "\n",
    "- Create a color image of size 640x480, with random pixels\n",
    "\n",
    "**Beware:** the order of the colors in the third dimension when writing is BGR, not RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_white = np.zeros((480,640,3), dtype=np.uint8)+255\n",
    "img_red_square = img_white.copy()\n",
    "\n",
    "img_red_square[480/2-50:480/2+50,640/2-50:640/2+50,[1,2]] = 0\n",
    "img_noise = np.random.randint(0,256,(480,640,3),dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite('white.jpg', \n",
    "    cv2.cvtColor(img_white, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite('red_square.jpg',\n",
    "    cv2.cvtColor(img_red_square, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite('noise.jpg',\n",
    "    cv2.cvtColor(img_noise, cv2.COLOR_RGB2BGR))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Color Spaces\n",
    "\n",
    "Converting between color spaces\n",
    "\n",
    "- The default colorspace in OpenCV is BGR.\n",
    "\n",
    "- You can convert images from and to many color spaces with `cvtColor`, e.g.:\n",
    "\n",
    "```python\n",
    "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "```\n",
    "\n",
    "- You can get a list of all possible color conversions by typing:\n",
    "\n",
    "```python \n",
    "for flag in dir(cv2):\n",
    "    if flag.startswith('COLOR_'):\n",
    "        print(flag)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flag in dir(cv2):\n",
    "    if flag.startswith('COLOR_'):\n",
    "        print(flag)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "...\n",
    "COLOR_BGRA2GRAY\n",
    "COLOR_BGRA2RGB\n",
    "COLOR_BGRA2RGBA\n",
    "...\n",
    "COLOR_GRAY2BGR\n",
    "...\n",
    "COLOR_GRAY2BGRA\n",
    "COLOR_GRAY2RGB\n",
    "COLOR_GRAY2RGBA\n",
    "COLOR_HLS2BGR\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the lena image to HSV (hue-saturation-value) and save the saturation as a grayscale image\n",
    "- Saturate the image by setting the S channel to 255 and save it as a color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lena_bgr = cv2.imread('lena.jpg',cv2.IMREAD_COLOR)\n",
    "lena_hsv = cv2.cvtColor(lena_bgr, cv2.COLOR_BGR2HSV)\n",
    "cv2.imwrite('lena-saturation.jpg',lena_hsv[:,:,1])\n",
    "\n",
    "lena_saturated = lena_hsv.copy()\n",
    "lena_saturated[:,:,1] = 255\n",
    "lena_saturated = cv2.cvtColor(lena_saturated, cv2.COLOR_HSV2BGR)\n",
    "cv2.imwrite('lena-saturated.jpg',lena_saturated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Point Operation: Thresholding\n",
    "\n",
    "- The thresholding operation is to create a *destination* image $g$ from a *source* image $f$ by replacing each pixel of the original image $f$ with 255 if the pixel intensity is above a threshold $T$, and by 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    g(i, j) = \\begin{cases}\n",
    "                255 \\quad \\text{ if } f(i, j) > T \\\\\n",
    "                0   \\quad \\text{ otherwise.}\n",
    "            \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply a threshold $T=127$ on the grayscale image of Lena `img_gray` and save the result to `lena-thresholded.jpg`. You can either:\n",
    "    + Iterate over the two coordinates and set the pixel intensity of the target image/array:\n",
    "\n",
    "    ```python\n",
    "    for i in range(img_gray.shape[0]):\n",
    "        for j in range(img_gray.shape[1]):\n",
    "            thresholded[i, j] = ...\n",
    "    ```\n",
    "    \n",
    "    + Or you use boolean arrays for sub-indexing:\n",
    "\n",
    "    ```python\n",
    "    thresholded[img_gray > T] = ...\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the lena image\n",
    "T = 127\n",
    "thresholded = np.zeros(img_gray.shape, dtype=np.uint8)\n",
    "for i in range(img_gray.shape[0]):\n",
    "    for j in range(img_gray.shape[1]):\n",
    "        if img_gray[i, j] > T:\n",
    "            thresholded[i, j] = 255\n",
    "cv2.imwrite('lena-thresholded.jpg', thresholded)\n",
    "\n",
    "# or :\n",
    "thresholded = img_gray.copy()\n",
    "thresholded[thresholded > T] = 255\n",
    "thresholded[thresholded <= T] = 0\n",
    "cv2.imwrite('lena-thresholded2.jpg', thresholded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modify the thresholding procedure so that above-threshold pixels are converted to red, not white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the lena image reddish \n",
    "red_lena = np.zeros(img_color.shape, dtype=np.uint8)\n",
    "red_lena[:, :, 0] = thresholded\n",
    "cv2.imwrite('lena-red.jpg', cv2.cvtColor(red_lena, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another solution to threshold an image is to use the OpenCV function `threshold`:\n",
    "\n",
    "```python\n",
    "ret, th = cv2.threshold(img_gray,thresh=127, \n",
    "                        maxval=255, type=cv2.THRESH_BINARY)\n",
    "```\n",
    "\n",
    "- There are many threshold types to investigate:\n",
    "\n",
    "![img/threshold.jpg](img/threshold.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the lena image using cv2.threshold()\n",
    "ret, thresholded = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('lena-thresholded3.jpg', thresholded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply thresholding on the `sudoku.jpg` image. Try to find a threshold that works to extract all printed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the sudoku image\n",
    "sudoku_gray = cv2.imread('sudoku.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "ret, thresholded = cv2.threshold(sudoku_gray, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('sudoku-thresholded.jpg', thresholded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does it work well? Why is it difficult to find a suitable threshold value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now: apply the adaptive thresholding on the `sudoku.jpg` image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive threshold for the sudoku image\n",
    "sudoku_gray = cv2.imread('sudoku.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "thresholded2 = cv2.adaptiveThreshold(sudoku_gray, 255\n",
    "            , cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "cv2.imwrite('sudoku-thresholded2.jpg', thresholded2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Global Operation: Histogram Equalization\n",
    "\n",
    "- Build and plot an histogram $h(I)$ of pixel intensities in the grayscale lena\n",
    "\n",
    "- Build and plot the corresponding cumulative histogram $c(I)$\n",
    " \n",
    "$$ c(I) = \\frac{1}{N} \\sum_{i=0}^I h(i) = c(I-1) + \\frac{1}{N} h(I) $$\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"img/lena-histo.png\" alt=\"img/lena-histo.png\\\" width=\"300\"/>\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"img/lena-cumhisto.png\" alt=\"img/lena-cumhisto.png\" width=\"300\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a histogram of pixel intensities\n",
    "hist = np.zeros(256)\n",
    "for i in range(img_gray.shape[0]):\n",
    "    for j in range(img_gray.shape[1]):\n",
    "        hist[img_gray[i, j]] += 1\n",
    "\n",
    "# Compute the cumulative histogram\n",
    "cum_hist = np.zeros(256)\n",
    "N = img_gray.size\n",
    "cum_hist[0] = hist[0]/N\n",
    "for p in range(1,256):\n",
    "    cum_hist[p] = cum_hist[p-1] + hist[p]/N\n",
    "\n",
    "plt.subplot(121)    \n",
    "plt.plot(hist)\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('Pixel intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "\n",
    "# or directly:\n",
    "# plt.subplot(121)    \n",
    "# plt.hist(img_gray.flatten(), 256, [0,256])\n",
    "\n",
    "plt.subplot(122)    \n",
    "plt.plot(cum_hist)\n",
    "plt.title('Cumulative histogram')\n",
    "plt.xlabel('Pixel intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Equalize the grayscale lena and save it to disk. Compare.\n",
    "\n",
    "$$ g(i, j) = 255 \\times c(f(i, j)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equalize the histogram\n",
    "equalized = np.zeros(img_gray.shape, dtype=np.uint8)\n",
    "for i in range(img_gray.shape[0]):\n",
    "    for j in range(img_gray.shape[1]):\n",
    "        equalized[i, j] = 255 * cum_hist[img_gray[i][j]]\n",
    "\n",
    "cv2.imwrite('lena-equalized.jpg', equalized)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenCV has a `equalizeHist(img_gray)` method that does the same operation. Compare its result with yours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using OpenCV:\n",
    "equalized = cv2.equalizeHist(img_gray)\n",
    "cv2.imwrite('lena-equalized2.jpg', equalized) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Local Operation: Locally Adaptive Histogram Equalization\n",
    "\n",
    "- The problem with histogram equalization is that it uses **global** information about the image\n",
    "\n",
    "- **Locally adaptive histogram equalization** (CLAHE) performs histogram equalization **locally** around each pixel.\n",
    "\n",
    "<img src=\"img/clahe.png\" alt=\"img/clahe.png\" width=\"300\"/>\n",
    "<!-- ![](img/clahe.png) -->\n",
    "\n",
    "$$ c(f(i, j)) = d_1(i, j) c_1(f(i, j)) + d_2(i, j) c_2(f(i, j)) + d_3(i, j) c_3(f(i, j)) + d_4(i, j) c_4(f(i, j)) $$\n",
    "\n",
    "- OpenCV allows to apply directly this algorithm on an image:\n",
    "\n",
    "```python\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "cl = clahe.apply(img)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply the CLAHE algorihm on the images lena and sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "clahe_lena = clahe.apply(img_gray)\n",
    "cv2.imwrite('lena-clahe.jpg', clahe_lena)\n",
    "\n",
    "clahe_sudoku = clahe.apply(sudoku_gray)\n",
    "cv2.imwrite('sudoku-clahe.jpg', clahe_sudoku)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Color Filters\n",
    "\n",
    "We want to filter out the feathers on Lena's hat. Their color has a hue between 120 and 160.\n",
    "\n",
    "- Create a color image where only the feathers are colored as in the original, the rest being gray.\n",
    "\n",
    "The algorithm is basically:\n",
    "\n",
    "1. Convert the color image to HSV.\n",
    "\n",
    "2. Convert the gray image to BGR to store the result.\n",
    "\n",
    "3. For all pixels:\n",
    "\n",
    "    + If the hue is between 120 and 160, write the original BGR color vector to the result image.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a first try, make a double for-loop over the pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv  = cv2.cvtColor(img_color, cv2.COLOR_BGR2HSV)\n",
    "gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "result = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "hue_min = 120\n",
    "hue_max = 160\n",
    "\n",
    "for i in range(img_color.shape[0]):\n",
    "    for j in range(img_color.shape[1]):\n",
    "        if hsv[i,j,0]> hue_min and  hsv[i,j,0]< hue_max:\n",
    "            result[i,j,:] = img_color[i,j,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a second try, try to think about what this function does:\n",
    "\n",
    "```python\n",
    "hue = hsv[:, :, 0]\n",
    "np.bitwise_and(hue > 120, hue < 160)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv  = cv2.cvtColor(img_color, cv2.COLOR_BGR2HSV)\n",
    "gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "result = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "pixels = np.bitwise_and( hsv[:,:,0]> hue_min, hsv[:,:,0]< hue_max)\n",
    "result[pixels,:] = img_color[pixels, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done, put your code into a function, we will need it later:\n",
    "\n",
    "```python\n",
    "def hue_filter(img, hue_min, hue_max):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the violet color\n",
    "def hue_filter(img_color, hue_min, hue_max):\n",
    "    hsv  = cv2.cvtColor(img_color, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    result = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)    \n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(img_color.shape[0]):\n",
    "        for j in range(img_color.shape[1]):\n",
    "            if hsv[i,j,0]> hue_min and  hsv[i,j,0]< hue_max:\n",
    "                result[i,j,:] = img_color[i,j,:]\n",
    "    \"\"\"\n",
    "    \n",
    "    pixels = np.bitwise_and( hsv[:,:,0]> hue_min, hsv[:,:,0]< hue_max)\n",
    "    result[pixels,:] = img_color[pixels, :]\n",
    "        \n",
    "    return result\n",
    "\n",
    "violet_filtered = hue_filter(img_color, 120, 160)\n",
    "cv2.imwrite('lena-violet-filtered.jpg', violet_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Videos\n",
    "\n",
    "### 9.A. Opening A Video\n",
    "\n",
    "You can read a video frame-by-frame with the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('video.ogv')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        #frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame', frame)\n",
    "    else:\n",
    "        break\n",
    "    k = cv2.waitKey(5) & 0xFF # Sleep 5 ms\n",
    "    if k == 27: # Press ESC to close\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Put the code in a script `vread.py` and run it from a terminal\n",
    "\n",
    "```bash\n",
    "$ python vread.py\n",
    "```\n",
    "\n",
    "- Open the script again and remove the comment mark `#` in the `if` statement in odrer to call the function `frame = cv2.cvtColor()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can read different video format supported by ffmpeg/gstreamer on Linux:\n",
    "\n",
    "    * H264 (.mp4)\n",
    "    * WebM (.webm)\n",
    "    * AVI (.avi)\n",
    "    * Theora (.ogv)\n",
    "    * DivX, WMV...\n",
    "\n",
    "- In the B202, you have only access to `.ogv` videos (non-free codecs issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.B. Writing A Video\n",
    "\n",
    "Saving a video is just as easy. Copy the code to a script `vwrite.py` and run it:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# vwrite.py: writing a video\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# create VideoWriter object\n",
    "out = cv2.VideoWriter( \n",
    "    filename='video-square.ogv', \n",
    "    fourcc=cv2.VideoWriter_fourcc(*'THEO'), \n",
    "    fps=30.0, \n",
    "    frameSize=(560,320)\n",
    ")\n",
    "\n",
    "\n",
    "for f in range(90):\n",
    "    frame = np.zeros((320,560), np.uint8)\n",
    "    frame[160 - 50 + 2*f: 160 + 50 + 2*f, \n",
    "         280 - 50 + 2*f: 280 + 50 + 2*f] = 255\n",
    "    out.write(cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "out.release()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You only need to choose the right codec for the `fourcc` argument.\n",
    "\n",
    "    + `'H264'` for mp4.\n",
    "    + `'XVID'` for avi.\n",
    "    + `'THEO'` for theora. \n",
    "\n",
    "- **Only Theora works in B202**\n",
    "- See <http://www.fourcc.org>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercises\n",
    "\n",
    "### 10.A. Processing Videos\n",
    "\n",
    "- Read the given video `video.ogv` and save the grayscale version in `video-gray.ogv`.\n",
    "\n",
    "- Apply a color filter on each frame and filter the blue color (hue between 100 and 130).\n",
    "\n",
    "- Compare the time needed for this last conversion when using the double for-loops, and the `numpy.bitwise_and` method.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
